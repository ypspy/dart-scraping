# -*- coding: utf-8 -*-
"""
Created on Thu Aug 13 15:19:08 2020

@author: user
"""

from bs4 import BeautifulSoup
import os
import glob
import pandas as pd
import numpy as np

def col_span_count(soup):
    try:
        result = int(soup["colspan"])
    except KeyError:
        result= 1
    return result

def row_span_count(soup):
    try:
        result = int(soup["rowspan"])
    except KeyError:
        result= 1
    return result

def FindTargetTable(soup):
    tables = soup.find_all("table")
    for i in tables:
        tds = i.find_all("td")
        if len(tds) > 20:  # 시간 파트가 약 80정도 된다. 비교 표시 없는 경우 td가 50도 안된다. 첫번째 나오는 20 초과 table 선택
            break
    return i

def MatrixGenerator(table):
    table_row = table.find_all("tr")

    columnCount = 0
    for i in table_row:
        columnNumber = 0
        for j in i.find_all(["th", "td"]):
            try:
                columnNumber += int(j["colspan"])
            except KeyError:
                columnNumber += 1
            if columnNumber > columnCount:
                columnCount = columnNumber        
    rowCount = len(table_row)
    matrix = [['#' for x in range(columnCount)] for y in range(rowCount)] 
    for i in range(len(table_row)):
        locator = [i for i, x in enumerate(matrix[i]) if x=='#']  # https://stackoverflow.com/questions/9542738/python-find-in-list
        column, colSpan = 0, 0
        for j in table_row[i].find_all(["th", "td"]):
            rowSpanCount = row_span_count(j)
            colSpanCount = col_span_count(j)

            for k in range(rowSpanCount):
                for l in range(colSpanCount):
                    row = i + k
                    column = locator[l+colSpan]
                    matrix[row][column] = j.text.strip()
            colSpan += col_span_count(j)
    return matrix

# 1. 작업 폴더로 변경
os.chdir("c:\data\\")

# 2. 타겟 폴더에 있는 필요 문서 경로 리스트업
pathList = []
for path in [".\A001_2017\\", ".\A001_2018\\",
              ".\A001_2019\\", ".\A001_2020\\",
              ".\F001_2017\\", ".\F001_2018\\",
              ".\F001_2019\\", ".\F001_2020\\",
              ".\F002_2017\\", ".\F002_2018\\",
              ".\F002_2019\\", ".\F002_2020\\"]:

    path = path + "*(첨부)*.*"  # 필요한 Keyword 입력
    pathInProcess = glob.glob(path)
    pathList= pathList + pathInProcess

# 3. 입수 과정에서 중복입수되어 표시된 duplicated 표시 파일 제거
pathList = [x for x in pathList if "duplicated" not in x]

# 4. 분리
pathList = [x for x in pathList if "(2017." in x] + [x for x in pathList if "(2018." in x] + [x for x in pathList if "(2019." in x] 

# 5. Preprocess
PathListDf = pd.DataFrame(pathList)
df = pd.DataFrame([x.split("_") for x in pathList])
df["path"] = PathListDf[0]
df["con"] = df[6].str.contains("연결")
df['con'] = np.where(df['con']==True, "C", "S")
df['amend'] = df[6].str.contains("정정")
df['amend'] = np.where(df['amend']==True, "A", "B")
df["key"] = df[2] + df[6].str.slice(stop=10) + df["con"] + df["amend"] + df[5] + df[8] + df[10]
# key = 접수일 + 보고서 제출일(DRT 인증일) + 연결(C/S) + 정정(A/B) + 보고기간종료월 + 종목코드 + 법인등록번호

df["duplc"] = df.duplicated(subset=["key"], keep=False)
isTrue = df[df["duplc"] == True]
df = df.drop_duplicates(subset=["key"])

pathListOut = df["path"].tolist()

result = []
count = 0

for file in pathListOut:

    html = open(file, "r", encoding="utf-8")
    soup = BeautifulSoup(html, "lxml")
    html.close()

    soup = str(soup).split("주석</A>")[0]
    soup = soup.replace("\n", '')
    soup = BeautifulSoup(soup, "lxml")
    
    # 단위 추출
    for td in soup.find_all(["p","td"]):
        if ''.join(td.text.split()).find("단위") > 0:
            unit = ''.join(td.text.split())
            if unit.find(":원") > 0:
                unit = '1'
            elif unit.find(":천원") > 0:
                unit = '1000'
            elif unit.find(":백만원") > 0:
                unit = '1000000'
            else:
                unit = "NA"           
            break

    # IS 찾기
    
    for table in soup.find_all("table"):
        if ''.join(table.text.split()).find("당기순") > 0:
            break
        table = BeautifulSoup("<table></table>", features="lxml").table  # 의견 거절 등 BS가 안붙어있을 때 처리
    
    matrix = MatrixGenerator(table)
        
    # Net Income Parsing

    resultString = ''
    isLine = ''
    
    if len(matrix) > 0:  # IS가 있을 때
        
        exitKey = False
        for i in matrix:
           for j in i:

               matchesNeg = ["계속", "중단", "귀속"]
               
               if "당기순" in j and all(x not in j for x in matchesNeg):
                                        
                    if len(i) == 2:  # 오리온 (2018.12)
                        isLine = [i[0], unit, i[1].replace("=", "")]        
                    elif len(i) % 2 == 1:  # 주석 Column이 없을 때
                        if i[1]:
                            isLine = [i[0], unit, i[1].replace("=", "")]
                        elif i[2]:
                            isLine = [i[0], unit, i[2].replace("=", "")]
                    else:  # 주석 Column이 있을 때
                        if i[2]:
                            isLine = [i[0], unit, i[2].replace("=", "")]
                        elif i[3]:
                            isLine = [i[0], unit, i[3].replace("=", "")]
        
                    resultString = "_".join(isLine)
                    exitKey = True                    
                    break
            
           if exitKey == True:
               break

    elif len(matrix) == 0:  # BS가 없을 때
        resultString = ""
    
    result.append(resultString)
    count += 1
    print(count, end='  ')

df["netIncome"] = result

df = df.drop([0, 1, 14, "path", "duplc"], axis=1)
df = df.sort_values(by=[10, 5, "con", 2, 6, "amend"],
                    ascending=[True, True, True, False, False, True])

df["toDrop"] = 1

for i in range(1, len(df)):
    if df.iloc[i,3] == df.iloc[i-1,3] and df.iloc[i,8] == df.iloc[i-1,8]:
        df.iloc[i, 16] = df.iloc[i-1, 16] + 1
    else:
        df.iloc[i, 16] = 1

df = df[df["toDrop"] == 1]
df = df.drop("toDrop", axis=1)

os.chdir(r"C:\\Users\\yoont\\Desktop\\output\\") 
df.to_csv("wp01.data14.output.csv", sep="\t")
